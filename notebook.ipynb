{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Langevin algorithms for very deep Neural Networks with applications to image classification</h1>\n",
    "\n",
    "We show how to:\n",
    "<ol>\n",
    "    <li>Use Langevin optimizers and Layer Langevin optimizers for any Tensorflow model training</li>\n",
    "    <li>Use our framework for comparing differents optimizers on a same image classification (or general) problem</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1) Langevin Optimizers</h2>\n",
    "\n",
    "Optimizers in the <tt>optimizers</tt> directory can be directly used as instances of the TensorFlow <tt>Optimizer</tt> base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers.ladam import LAdam, LayerLAdam\n",
    "from optimizers.lrmsprop import LRMSprop, LayerLRMSprop\n",
    "from optimizers.ladadelta import LAdadelta, LayerLAdadelta\n",
    "\n",
    "optimizer = LAdam(learning_rate=1e-3, sigma=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedules from <tt>tf.keras.optimizers.schedules</tt> may be passed to the arguments <tt>learning_rate</tt> and to <tt>sigma</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[100], values=[1e-3,1e-4])\n",
    "sigma_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[100], values=[1e-3,0.])\n",
    "\n",
    "optimizer = LAdam(learning_rate=lr_schedule, sigma=sigma_schedule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Layer Langevin optimizers</b>\n",
    "\n",
    "The argument <tt>langevin_layers</tt> specify the layers of the model that are trained with Langevin noise.\n",
    "\n",
    "When using Layer Langevin optimizers, the function <tt>set_langevin(model)</tt> must be used after the <tt>model</tt> is compiled with this optimizer and built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers.base import set_langevin\n",
    "\n",
    "optimizer = LayerLAdam(learning_rate=1e-3, sigma=1e-3, langevin_layers=[0,1])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "model(tf.random.normal((1,5))) # build the model\n",
    "set_langevin(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2) Running an experiment for Image Classification</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Builder:</b>\n",
    "\n",
    "A <tt>ModelBuilder</tt> is required for the <tt>experiment</tt>.\n",
    "We provide different <tt>ModelBuilder</tt>s: <tt>DenseModel</tt>, <tt>ConvDense</tt>, <tt>HighwayModel</tt>, <tt>ResNet</tt>, <tt>DenseNet</tt>.\n",
    "Each <tt>ModelBuilder</tt> has the method <tt>getModel()</tt> which returns a TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dense import DenseModel\n",
    "from models.conv_dense import ConvDense\n",
    "from models.highway import HighwayModel\n",
    "from models.resnet import ResNet\n",
    "from models.densenet import DenseNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><tt>DenseModel(nb_units, classes)</tt></b>: Fully connected model.\n",
    "<ul>\n",
    "    <li><tt>nb_units</tt>: list of units in each hidden layer; each hidden layer has ReLU activation</li>\n",
    "    <li><tt>classes</tt>: number of classes for the output.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<b><tt>ConvDense(nb_units, classes)</tt></b>: Convolutional layers before a fully connected layers.\n",
    "<ul>\n",
    "    <li><tt>nb_conv</tt>: number of 2D convolutional layers</li>\n",
    "    <li><tt>filters</tt>, <tt>kernel_size</tt>: parameters of the 2D convolutional layers</li>\n",
    "    <li><tt>nb_units</tt>: list of units in each hidden dense layer; each hidden layer has ReLU activation</li>\n",
    "    <li><tt>classes</tt>: number of classes for the output</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<b><tt>HighwayModel(nb_units, classes)</tt></b>: Same as <tt>DenseModel(nb_units, classes)</tt> but the dense hidden layers are replaced with highway layers and one dense layer is used before the highway layers. All the hidden layers must have the same number of units.\n",
    "\n",
    "\n",
    "<b><tt>ResNet(input_shape,filters,block_layers,hidden_units,classes,zero_padding,mode)</tt></b>:\n",
    "<ul>\n",
    "    <li><tt>input_shape</tt>: 3-tuple of (width, height, channels)</li>\n",
    "    <li><tt>filters</tt>: initial number of filters in the ResNet architecture (multiplied by two at every new block)</li>\n",
    "    <li><tt>block_layers</tt>: list of number of residual layers in each block</li>\n",
    "    <li><tt>hidden_units</tt></li>\n",
    "    <li><tt>classes</tt>: number of classes for the output</li>\n",
    "    <li><tt>zero_padding</tt>: 2-tuple for zero padding in each direction</li>\n",
    "    <li><tt>mode</tt>: either <tt>\"resnet\"</tt> or <tt>\"vgg\"</tt>; if <tt>\"vgg\"</tt> then removes the residual connections</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<b><tt>DenseNet(input_shape, classes)</tt></b>: DenseNet-121 architecture. <tt>input_shape</tt> is a 3-tuple and width and height should be no smaller than 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ResNet(\n",
    "    input_shape=(32, 32, 3),\n",
    "    filters=16,\n",
    "    block_layers=[5,5,5],\n",
    "    hidden_units=512,\n",
    "    classes=10,\n",
    "    zero_padding=(0, 0),\n",
    "    mode='resnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataloader</b> with\n",
    "\n",
    "<tt>ImageLoader(dataset_name,batch_size,rescale,augment)</tt>.\n",
    "<ul>\n",
    "    <li><tt>dataset_name</tt>: either \"mnist\", \"cifar10\" or \"cifar100\", or any other dataset available in <tt>tensorflow_datasets</tt></li>\n",
    "    <li><tt>rescale</tt>, <tt>augment</tt>: tensorflow batchable functions that takes as argument a batch of images and returns the rescaled and augmented images\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import ImageLoader\n",
    "\n",
    "batch_size = 512\n",
    "def rescale(x):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    return x/255.\n",
    "\n",
    "def augment(x):\n",
    "    x = tf.image.resize_with_crop_or_pad(x, 32 + 4, 32 + 4)\n",
    "    x = tf.image.random_crop(x,[32,32,3])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "\n",
    "dataloader = ImageLoader(\n",
    "    dataset_name = 'cifar10',\n",
    "    batch_size = batch_size,\n",
    "    rescale = rescale,\n",
    "    augment = augment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then build the <tt>experiment</tt> with additional arguments:\n",
    "<ul>\n",
    "    <li><tt>optimizers</tt>: list of tensorflow optimizers to compare</li>\n",
    "    <li><tt>base</tt>: path to save the results</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    model_builder=model_builder,\n",
    "    dataloader=dataloader,\n",
    "    EPOCHS=20,\n",
    "    optimizers=[LAdam(learning_rate=1e-3, sigma=1e-3),\n",
    "                LAdam(learning_rate=1e-3, sigma=0.)],\n",
    "    base='./')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><tt>experiment.load_data()</tt>: load the data according to the dataloader; must be used before any training</li>\n",
    "    <li><tt>experiment.run_experiment()</tt>: train the model for each optimizer</li>\n",
    "    <li><tt>experiment.plot()</tt>: plot the training curves for each optimizer</li>\n",
    "    <li><tt>experiment.save_data(dir)</tt>: save the training curves as <tt>csv</tt> files in the <tt>experiment.base/dir</tt> directory (the directory is created)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.load_data()\n",
    "experiment.run_experiment()\n",
    "experiment.plot()\n",
    "\n",
    "experiment.save_data('cifar10_adam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "755bca588c5ad61560da42c0cec298747f8b74f9b58b010e18f102b95c79ceda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
